{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Many Sources of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import requests as rq\n",
    "from bs4 import BeautifulSoup\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from matplotlib import pyplot as plt\n",
    "import wave\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tables\n",
    "\n",
    "Stereotypically, data comes in the form of *spreadsheets* or *tables*, with a row-and-column structure.\n",
    "\n",
    "This is still very much a popular source of data for the practicing data scientist. In the raw code for such data files, the individual values in the different cells are often separated by commas or by `tab` characters. (These are often good choices since these characters rarely appear in tables themselves and so there is generally little chance for ambiguity.)\n",
    "\n",
    "### .csv ($\\underline{c}$omma-$\\underline{s}$eparated $\\underline{v}$alues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This data taken from the Australian Institute of Health and Welfare:\n",
    "# https://www.aihw.gov.au/data-by-subject.\n",
    "\n",
    "pd.read_csv('../data/aihw-phc-4-csv/PHN_ERP_CSV.csv').head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use *VIM* to see the commas in the raw data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### .tsv ($\\underline{t}$ab-$\\underline{s}$eparated $\\underline{v}$alues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This data taken from Peter Norvig's pytudes:\n",
    "# https://github.com/norvig/pytudes.\n",
    "# It's a list of his bike rides that were longer\n",
    "# than 25 miles. The sixth column records the\n",
    "# elevation change.\n",
    "\n",
    "pd.read_csv('../data/bikerides25.tsv',\n",
    "           delimiter='\\t',\n",
    "           header=None).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use *VIM* to see the `tab`s in the raw data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clickstreams\n",
    "\n",
    "But data gets generated in lots of different ways these days. Sometimes the data of interest are patterns in the clicks of a website's users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This data taken from https://github.com/mafudge/datasets.\n",
    "# It is a set of sample weblogs from a Seattle e-commerce\n",
    "# website called \"nopCommerce\".\n",
    "\n",
    "stream = []\n",
    "with open('../data/u_ex160211.log') as f:\n",
    "    clicks = f\n",
    "    for click in clicks:\n",
    "        stream.append(click.replace('\\n', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## APIs\n",
    "\n",
    "An $\\underline{A}$pplication $\\underline{P}$rogramming $\\underline{I}$nterface, or API, is a generic term to describe how various bits of software interact with users or with each other. [Foursquare](https://foursquare.com/) is an application that allows developers to supplement their own applications with information about geographical location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://api.foursquare.com/v2/venues/explore'\n",
    "with open('../.secrets/credentials.json') as f:\n",
    "    params = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['v'] = '20201201'\n",
    "params['ll'] = '34, -118',\n",
    "params['query'] = 'tacos',\n",
    "params['intent'] = 'browse',\n",
    "params['radius'] = 100000,\n",
    "params['limit'] = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = rq.get(url=url, params=params)\n",
    "data = json.loads(response.text)\n",
    "[(item['venue']['name'], item['venue']['location']) for item\\\n",
    " in data['response']['groups'][0]['items']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sraping from the Web\n",
    "\n",
    "There is also a ton of data just sitting on various webpages. If need be, data scientists can also access data by cracking into the HTML code underlying the webpages that have the data of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.pro-football-reference.com/'\n",
    "\n",
    "res = rq.get(url)\n",
    "soup = BeautifulSoup(res.content, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams = []\n",
    "table = soup.find('table', {'id': 'AFC'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in table.find('tbody').find_all('tr'):\n",
    "    try:\n",
    "        team = {'name': row.find('th', {'data-stat': 'team'}).text,\n",
    "               'wins': row.find('td', {'data-stat': 'wins'}).text,\n",
    "               'losses': row.find('td', {'data-stat': 'losses'}).text,\n",
    "               'ties': row.find('td', {'data-stat': 'ties'}).text}\n",
    "        teams.append(team)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text - Natural Language Processing\n",
    "\n",
    "Data-processing tools have become so sophisticated that even long-form bits of text are useful these days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a list of the texts of all 58 Presidential inaugural addresses.\n",
    "# Most of them can be found here: https://avalon.law.yale.edu/subject_menus/inaug.asp.\n",
    "\n",
    "with open('../data/speeches.pkl', 'rb') as f:\n",
    "    speeches = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speeches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "pd.DataFrame(cv.fit_transform(speeches).todense(),\n",
    "             columns=cv.get_feature_names()).iloc[:10, 71:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Audio Files\n",
    "\n",
    "Audio files these days are created digitally, and so, even though we experience them most immediately as *sounds*, the digital encoding means that they're data as well! If we want to, we can access their digital descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One second from Elivs Presley's \"All Shook Up\",\n",
    "# courtesy of https://www.wavsource.com.\n",
    "\n",
    "with wave.open('../data/all_shook_up.wav') as f:\n",
    "    stats = f.getparams()\n",
    "    frames = f.readframes(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The numbers here represent the volume for a 16-bit mono track.\n",
    "\n",
    "frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Images\n",
    "\n",
    "An image is a visual object, of course. But again there are digital representations of them that bring them into the domain of data science. A digital image is a grid of pixels, and each pixel contains a part of the image. Each part of the image has a color, and we can represent any color by a number or sequence of numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are images of handwritten digits, 0-9.\n",
    "# Here's a 9.\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "plt.imshow(mnist.load_data()[0][0][4]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And here's a digital representation of that same 9.\n",
    "\n",
    "mnist.load_data()[0][0][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
